{
    "Identifier": "eos9zw0",
    "Slug": "molpmofit",
    "Status": "In progress",
    "Title": "Molecular Prediction Model Fine-Tuning (MolPMoFiT)",
    "Description": "Using self-supervised learning, the authors pre-trained a large model using one millon unlabelled molecules from ChEMBL. This model can subsequently be fine-tuned for various QSAR tasks. Here, we provide the encodings for the molecular structures using the pre-trained model, not the fine-tuned QSAR models.",
    "Mode": "",
    "Task": [],
    "Input": [],
    "Input Shape": "",
    "Output": [],
    "Output Type": [],
    "Output Shape": "",
    "Interpretation": "",
    "Tag": [
        "Descriptor",
        "Embedding"
    ],
    "Publication": "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00430-x",
    "Source Code": "https://github.com/XinhaoLi74/MolPMoFiT",
    "License": "None"
}